% Appendix C: Additional Proofs
%
% This appendix contains detailed proofs of key theorems that were
% stated without full proof in the main text.

\chapter{Additional Proofs}
\label{app:proofs}

This appendix provides detailed proofs of key theorems that were stated
without full derivation in the main chapters. All proofs can be verified
in the Lean formalization (Appendix~\ref{app:lean}).

\section{Confidence Algebra Proofs}

\subsection{Theorem: Oplus Preserves Bounds}

\begin{theorem}[Oplus Boundedness]
For all $a, b \in [0,1]$, we have $a \oplus b \in [0,1]$.
\end{theorem}

\begin{proof}
Recall that $a \oplus b = a + b - ab$.

\textbf{Lower bound}: We need $a + b - ab \geq 0$.
\begin{align}
a + b - ab &= a + b(1-a) \\
&\geq 0 + 0 \cdot (1-a) && \text{since } a,b \geq 0 \\
&= 0
\end{align}

\textbf{Upper bound}: We need $a + b - ab \leq 1$.
\begin{align}
a + b - ab &= a + b(1-a) \\
&\leq a + 1 \cdot (1-a) && \text{since } b \leq 1 \\
&= a + 1 - a \\
&= 1
\end{align}
\end{proof}

\subsection{Theorem: Undercut Composition}

\begin{theorem}[Undercut Composition via Oplus]
For all $c, d_1, d_2 \in [0,1]$:
$$\mathsf{undercut}(\mathsf{undercut}(c, d_1), d_2) = \mathsf{undercut}(c, d_1 \oplus d_2)$$
\end{theorem}

\begin{proof}
Expanding the left side:
\begin{align}
\mathsf{undercut}(\mathsf{undercut}(c, d_1), d_2)
&= \mathsf{undercut}(c(1-d_1), d_2) \\
&= c(1-d_1)(1-d_2)
\end{align}

Expanding the right side:
\begin{align}
\mathsf{undercut}(c, d_1 \oplus d_2)
&= c(1 - (d_1 \oplus d_2)) \\
&= c(1 - (d_1 + d_2 - d_1 d_2)) \\
&= c(1 - d_1 - d_2 + d_1 d_2)
\end{align}

Expanding $(1-d_1)(1-d_2)$:
\begin{align}
(1-d_1)(1-d_2) &= 1 - d_1 - d_2 + d_1 d_2
\end{align}

Therefore:
$$c(1-d_1)(1-d_2) = c(1 - d_1 - d_2 + d_1 d_2)$$

The two sides are equal.
\end{proof}

\subsection{Theorem: Non-Distributivity}

\begin{theorem}[Oplus and Multiplication Do Not Distribute]
The operations $\oplus$ and $\times$ do not satisfy distributivity:
$$a \times (b \oplus c) \neq (a \times b) \oplus (a \times c)$$
in general.
\end{theorem}

\begin{proof}
Counterexample: Let $a = b = c = 0.5$.

\textbf{Left side}:
\begin{align}
a \times (b \oplus c) &= 0.5 \times (0.5 \oplus 0.5) \\
&= 0.5 \times (0.5 + 0.5 - 0.25) \\
&= 0.5 \times 0.75 \\
&= 0.375
\end{align}

\textbf{Right side}:
\begin{align}
(a \times b) \oplus (a \times c) &= (0.5 \times 0.5) \oplus (0.5 \times 0.5) \\
&= 0.25 \oplus 0.25 \\
&= 0.25 + 0.25 - 0.0625 \\
&= 0.4375
\end{align}

Since $0.375 \neq 0.4375$, distributivity fails.
\end{proof}

\subsection{Theorem: Rebut Anti-Symmetry}

\begin{theorem}[Rebut Anti-Symmetry]
For all $a, b \in [0,1]$ with $a + b \neq 0$:
$$\mathsf{rebut}(a, b) + \mathsf{rebut}(b, a) = 1$$
\end{theorem}

\begin{proof}
\begin{align}
\mathsf{rebut}(a, b) + \mathsf{rebut}(b, a)
&= \frac{a}{a+b} + \frac{b}{a+b} \\
&= \frac{a + b}{a+b} \\
&= 1
\end{align}
\end{proof}

\section{Defeat Fixed-Point Proofs}

\subsection{Theorem: Existence of Defeat Fixed Points}

\begin{theorem}[Fixed-Point Existence via Brouwer]
Every CLAIR defeat graph has at least one fixed-point confidence assignment.
\end{theorem}

\begin{proof}
Let $G = (V, E)$ be a defeat graph with vertices $V$ (beliefs) and edges $E$
(defeat relations). Define the update function $F: [0,1]^{|V|} \to [0,1]^{|V|}$
where for each vertex $v$:
$$F_v(\mathbf{c}) = b_v \times \prod_{(u,v) \in E_{\mathsf{undercut}}} (1 - c_u)$$

This function:
\begin{enumerate}
\item Maps $[0,1]^{|V|}$ to itself (boundedness preservation)
\item Is continuous (compositions of continuous operations)
\end{enumerate}

Since $[0,1]^{|V|}$ is compact and convex, and $F$ is continuous, Brouwer's
Fixed-Point Theorem guarantees at least one fixed point.
\end{proof}

\subsection{Theorem: Uniqueness Under Contraction}

\begin{theorem}[Fixed-Point Uniqueness]
If $b_{\max} \times d_{\max} < 1$, where $b_{\max}$ is the maximum base
confidence and $d_{\max}$ is the maximum in-degree of undercuts, then the
fixed point is unique and iteration converges geometrically.
\end{theorem}

\begin{proof}
The Lipschitz constant of the update function $F$ is bounded by:
$$L = b_{\max} \times d_{\max}$$

When $L < 1$, $F$ is a contraction mapping. By the Banach Fixed-Point Theorem:
\begin{enumerate}
\item The fixed point is unique
\item Iteration converges: $\|c^{(n)} - c^*\| \leq L^n \|c^{(0)} - c^*\|$
\item Convergence rate is geometric with factor $L$
\end{enumerate}
\end{proof}

\subsection{Theorem: Mutual Undercut Fixed Point}

\begin{theorem}[Mutual Undercut Formula]
When two beliefs $A$ and $B$ undercut each other with base confidences $a$ and $b$,
the fixed-point confidences are:
$$A^* = \frac{a(1-b)}{1-ab}, \quad B^* = \frac{b(1-a)}{1-ab}$$
\end{theorem}

\begin{proof}
At fixed point, we have:
\begin{align}
A^* &= a(1 - B^*) \\
B^* &= b(1 - A^*)
\end{align}

Substituting the second into the first:
\begin{align}
A^* &= a(1 - b(1 - A^*)) \\
A^* &= a - ab + abA^* \\
A^* - abA^* &= a - ab \\
A^*(1 - ab) &= a(1 - b) \\
A^* &= \frac{a(1-b)}{1-ab}
\end{align}

By symmetry: $B^* = \frac{b(1-a)}{1-ab}$.

\textbf{Verification}: $A^*$ and $B^*$ satisfy the original equations:
\begin{align}
a(1 - B^*) &= a\left(1 - \frac{b(1-a)}{1-ab}\right) \\
&= a \cdot \frac{1 - ab - b(1-a)}{1-ab} \\
&= a \cdot \frac{1 - ab - b + ab}{1-ab} \\
&= a \cdot \frac{1 - b}{1-ab} \\
&= \frac{a(1-b)}{1-ab} = A^*
\end{align}
\end{proof}

\subsection{Theorem: Infinite Chain Convergence}

\begin{theorem}[Chain Limit]
An infinite chain of beliefs, each undercutting the next with constant
strength $d$, converges to confidence $\frac{d}{1+d}$.
\end{theorem}

\begin{proof}
Let $x_n$ denote the confidence of the $n$-th belief in the chain.
At fixed point: $x_n = d(1 - x_{n+1})$ for all $n$.

If the chain converges to a constant $x^*$:
\begin{align}
x^* &= d(1 - x^*) \\
x^* &= d - dx^* \\
x^* + dx^* &= d \\
x^*(1 + d) &= d \\
x^* &= \frac{d}{1+d}
\end{align}

This matches the Dung-style grounded semantics where odd-position arguments
attack and even-position arguments defend.
\end{proof}

\section{CPL Decidability Proofs}

\subsection{Theorem: CPL-finite Decidability}

\begin{theorem}[CPL-finite is Decidable]
CPL over a finite confidence lattice $L_n = \{0, \frac{1}{n}, \ldots, 1\}$
is decidable.
\end{theorem}

\begin{proof}[Proof Sketch]
Following Bou et al.~(2011):

\begin{enumerate}
\item \textbf{Finite Model Property}: Any satisfiable formula has a model
of bounded size (depends only on formula complexity and $|L_n|$).

\item \textbf{Decidable Model Checking}: Given a finite model $M$ and
formula $\varphi$, checking $M \models \varphi$ is decidable (computable
in finite time).

\item \textbf{Algorithm}: To decide satisfiability of $\varphi$:
\begin{enumerate}
\item Compute the size bound $B(\varphi, |L_n|)$
\item Enumerate all models up to size $B$
\item Check each model against $\varphi$
\item Return SAT if any model satisfies, UNSAT otherwise
\end{enumerate}
\end{enumerate}

The algorithm terminates because there are finitely many models up to size $B$.
\end{proof}

\subsection{Theorem: CPL Undecidability Argument}

\begin{theorem}[CPL is Likely Undecidable (Confidence: 0.80)]
Full CPL with continuous $[0,1]$ confidence is likely undecidable.
\end{theorem}

\begin{proof}[Proof Strategy]
The argument follows Vidal (2019) on transitive many-valued modal logics:

\begin{enumerate}
\item \textbf{Encoding Power}: Transitivity (axiom 4: $\Box A \to \Box\Box A$)
combined with continuous values allows encoding grid structures.

\item \textbf{Reduction}: Recurrent tiling problems can be encoded in CPL formulas.

\item \textbf{Key Insight}: Converse well-foundedness (required by L\"{o}b's axiom)
allows backward-looking infinite frames: $R(w_i, w_j) > 0$ iff $j < i$ satisfies
the constraint while still enabling tiling encodings.

\item \textbf{Conclusion}: If this encoding is correct, CPL satisfiability
reduces from an undecidable problem.
\end{enumerate}

The confidence level of 0.80 reflects that while the strategy is sound,
a complete formal verification requires additional technical work.
\end{proof}

\section{AGM Extension Proofs}

\subsection{Theorem: CLAIR Satisfies AGM Postulates (Modified)}

\begin{theorem}[CLAIR Satisfies Modified AGM]
CLAIR belief revision satisfies the following AGM postulates:
\begin{itemize}
\item (K*1) Closure: The result is a valid belief state
\item (K*2) Success: The new information is incorporated
\item (K*3) Inclusion: Only relevant changes are made
\item (K*4) Preservation: Unchanged beliefs are preserved
\item (K*5) Vacuity: Consistent addition doesn't require removal
\end{itemize}
CLAIR correctly \emph{violates} the controversial Recovery postulate (K*8).
\end{theorem}

\begin{proof}
\textbf{(K*1) Closure}: After modification, the DAG structure is preserved
(acyclicity maintained by construction), confidence values remain in $[0,1]$
(operations preserve bounds), and topological sorting produces valid results.

\textbf{(K*2) Success}: When adding evidence with edge $e$, the algorithm
inserts $e$ into the DAG and recomputes. The new edge is necessarily present.

\textbf{(K*3) Inclusion}: The Locality theorem (proven below) shows only
transitive dependents are affected. No spurious changes occur.

\textbf{(K*4) Preservation}: Beliefs with no path from modified nodes
have their confidence unchanged by the topological recomputation.

\textbf{(K*5) Vacuity}: Adding consistent evidence to a belief $B$
that doesn't contradict existing evidence only increases or maintains
$B$'s confidence (aggregation via $\oplus$ is monotonic).

\textbf{Recovery Violation}: Correctly fails because evidence has specific
strength. Removing evidence $e_1$ then re-adding $e_1$ may not restore the
original state if the epistemic context changed during retraction.
\end{proof}

\subsection{Theorem: Locality of Revision}

\begin{theorem}[Locality]
When an edge is modified in the justification DAG, only beliefs that are
transitive dependents of the modified node are affected.
\end{theorem}

\begin{proof}
By the structure of the recomputation algorithm:

\begin{enumerate}
\item The algorithm performs topological sort from the modified node
\item Only nodes reachable from the modified node are visited
\item Nodes not reachable have their confidence computed from unchanged inputs
\item Therefore, unreachable nodes' confidences are unchanged
\end{enumerate}

Formally: Let $R^*$ be the transitive closure of the ``depends on'' relation.
For any node $v$ with $(v, m) \notin R^*$ (where $m$ is the modified node),
the confidence $c_v$ is computed from inputs that are all unchanged,
so $c_v$ is unchanged.
\end{proof}

\section{Multi-Agent Proofs}

\subsection{Theorem: Collective Anti-Bootstrapping}

\begin{theorem}[Collective Anti-Bootstrapping]
Under CLAIR's multi-agent epistemology, unanimous agreement among agents
cannot produce confidence exceeding the maximum individual confidence,
and cannot reach confidence 1.0.
\end{theorem}

\begin{proof}
Let agents $A_1, \ldots, A_n$ have confidences $c_1, \ldots, c_n$ in
proposition $P$.

\textbf{Case 1}: Independent aggregation via $\oplus$.
The aggregate confidence is:
$$c_{\mathsf{agg}} = 1 - \prod_{i=1}^n (1 - c_i)$$

For $c_{\mathsf{agg}} = 1$, we would need $\prod(1-c_i) = 0$, which
requires some $c_i = 1$. But by individual anti-bootstrapping, no
agent can have $c_i = 1$. Therefore $c_{\mathsf{agg}} < 1$.

\textbf{Case 2}: Correlated aggregation with dependency $\delta$.
$$c_{\mathsf{agg}} = (1-\delta)(c_1 \oplus \cdots \oplus c_n) + \delta \cdot \frac{\sum c_i}{n}$$

Since both terms are less than 1 (by Case 1 and the fact that averages
of values $< 1$ are $< 1$), the interpolation is also $< 1$.

\textbf{Bound}: The maximum occurs at $\delta = 0$ (independence),
giving the $\oplus$-aggregate. As $n \to \infty$ with fixed $c_i = c < 1$:
$$c_{\mathsf{agg}} = 1 - (1-c)^n \to 1$$
but never equals 1 for finite $n$.
\end{proof}

% Chapter 2: Background & Related Work
% Surveys the intellectual context: epistemology, modal logic, TMS, argumentation, type theory

\chapter{Background \& Related Work}
\label{ch:background}

\epigraph{%
  ``If I have seen further it is by standing on the shoulders of Giants.''
}{Isaac Newton, letter to Robert Hooke (1675)}

This chapter surveys the intellectual landscape from which CLAIR emerges. We organize
the discussion around five major traditions: formal epistemology (\S\ref{sec:epistemology}),
modal and provability logic (\S\ref{sec:modal-logic}), truth maintenance and argumentation
systems (\S\ref{sec:tms-arg}), belief revision theory (\S\ref{sec:belief-revision-bg}), and
type-theoretic approaches to uncertainty (\S\ref{sec:type-theory-bg}). We conclude with
a synthesis (\S\ref{sec:synthesis}) identifying the gap CLAIR fills.

\section{Formal Epistemology}
\label{sec:epistemology}

Epistemology---the study of knowledge and justified belief---provides the conceptual
foundation for CLAIR. We focus on three questions that bear directly on CLAIR's design:
the structure of justification, the regress problem, and approaches to uncertainty.

\subsection{The Structure of Justification}
\label{subsec:justification-structure}

What does it mean for a belief to be justified? The classical answer involves giving
reasons. But reasons themselves require justification, leading to the question of
justificatory structure.

\paragraph{Foundationalism.}
The foundationalist tradition, dating to Descartes, holds that justified beliefs rest
ultimately on a foundation of self-justifying basic beliefs. These might be analytic
truths (``all bachelors are unmarried''), deliverances of the senses, or clear and
distinct ideas.

BonJour's \textit{The Structure of Empirical Knowledge}~\citep{bonjour1985structure}
provides the most thorough recent defense and critique of foundationalism. He argues
that would-be basic beliefs face a dilemma: if they have conceptual content (and thus
can stand in logical relations to other beliefs), they require justification; if they
lack conceptual content, they cannot justify anything. BonJour initially concluded
in favor of coherentism, though he later abandoned this view~\citep{bonjour1999defense}.

\paragraph{Coherentism.}
Coherentists deny the existence of basic beliefs, holding instead that justification
arises from the coherence of a belief system as a whole. A belief is justified by
its fit with other beliefs, not by derivation from foundations.

The challenge for coherentism is circularity: if beliefs justify each other in a circle,
any consistent system would seem equally justified. Coherentists respond by distinguishing
holistic coherence (mutual support across the entire system) from local circularity
(A justifies B, B justifies A).

\paragraph{Infinitism.}
Klein~\citep{klein1999human,klein2003infinite,klein2005infinitism} defends a third option:
the chain of justification extends infinitely without repeating. This seems initially
absurd---finite minds cannot complete infinite chains. Klein's response distinguishes
\emph{propositional justification} (reasons are available) from \emph{doxastic justification}
(reasons are actually believed). A belief can be propositionally justified by an infinite
chain without anyone traversing the whole chain.

\paragraph{Implications for CLAIR.}
CLAIR adopts what we call \emph{stratified coherentism}: a coherentist structure
with pragmatic foundations. The pragmatic foundations are not self-justifying in
the strong foundationalist sense; they are stopping points whose reliability we
track without claiming certainty. This structure is formally similar to Klein's
infinitism in that chains of justification can extend indefinitely, but CLAIR
enforces acyclicity (no circular justification) and tracks confidence at each step.

\subsection{Agrippa's Trilemma}
\label{subsec:agrippa}

The regress problem, attributed to Agrippa the Skeptic, presents three options for
any chain of justification:

\begin{enumerate}
  \item \textbf{Dogmatism}: The chain stops at some unjustified starting point.
  \item \textbf{Infinite regress}: The chain continues forever.
  \item \textbf{Circularity}: The chain loops back on itself.
\end{enumerate}

All three options seem problematic. Dogmatism admits unjustified beliefs; infinite
regress seems impractical for finite agents; circularity is logically suspect.

\paragraph{CLAIR's response.}
CLAIR accepts pragmatic dogmatism (option 1), mitigated by three features:
\begin{itemize}
  \item \textbf{Fallibilism}: Foundational beliefs have confidence $< 1$; they are
        provisional, not certain.
  \item \textbf{Transparency}: The lack of deeper justification is explicit in the
        justification DAG, not hidden.
  \item \textbf{Reliability tracking}: We track the source of foundational beliefs
        (training, observation, assumption) and can update if reliability evidence emerges.
\end{itemize}

Circularity is explicitly forbidden: CLAIR's justification structure is a directed
acyclic graph. Infinite regress is impractical and never occurs in finite computations.

\subsection{Probability vs.\ Epistemic Confidence}
\label{subsec:probability-vs-confidence}

Standard approaches to uncertain reasoning use probability theory. A probability
distribution over propositions assigns values in $[0,1]$ satisfying:
\begin{align}
  P(\top) &= 1 \\
  P(\phi \lor \psi) &= P(\phi) + P(\psi) - P(\phi \land \psi) \\
  P(\lnot\phi) &= 1 - P(\phi)
\end{align}

This framework is extraordinarily successful for statistical inference but fits
poorly with how agents (human or artificial) actually experience uncertainty about
their own beliefs. Two key mismatches:

\paragraph{Normalization.}
Probability requires $P(\phi) + P(\lnot\phi) = 1$. But an agent might be uncertain
about both $\phi$ and $\lnot\phi$---perhaps due to lack of information rather than
balanced evidence. When asked about an unfamiliar topic, the appropriate response
may be low confidence in \emph{both} the claim and its negation.

\paragraph{Paraconsistency.}
In probability, $P(\phi) > 0.5$ and $P(\lnot\phi) > 0.5$ is impossible. But agents
sometimes find themselves with evidence for both $\phi$ and $\lnot\phi$, without
immediately resolving the contradiction. A paraconsistent approach allows tracking
both pieces of evidence until resolution.

\paragraph{Subjective Logic.}
Jøsang's Subjective Logic~\citep{josang2016subjective} extends probability with explicit
uncertainty. An opinion $\omega = (b, d, u, a)$ consists of:
\begin{itemize}
  \item $b$: belief mass (evidence for)
  \item $d$: disbelief mass (evidence against)
  \item $u$: uncertainty mass (lack of evidence)
  \item $a$: base rate (prior probability)
\end{itemize}
with constraint $b + d + u = 1$. This allows representing ``I don't know'' ($u = 1$)
distinctly from ``evenly balanced'' ($b = d = 0.5, u = 0$).

\paragraph{CLAIR's approach.}
CLAIR's confidence is conceptually closer to Subjective Logic than to probability,
but simpler: a single value $c \in [0,1]$ representing epistemic commitment, without
the $b/d/u$ decomposition. The key departures from probability are:
\begin{itemize}
  \item No normalization: $\conf(\phi) + \conf(\lnot\phi)$ need not equal 1.
  \item $c = 0.5$ represents maximal uncertainty, not equal evidence.
  \item Operations (multiplication, aggregation) differ from Bayesian conditioning.
\end{itemize}

\section{Modal and Provability Logic}
\label{sec:modal-logic}

Modal logic studies necessity ($\Box$) and possibility ($\Diamond$). Epistemic logic
interprets $\Box\phi$ as ``the agent knows $\phi$'' or ``the agent believes $\phi$.''
Provability logic interprets $\Box\phi$ as ``$\phi$ is provable'' in a formal system.

\subsection{Epistemic Logic}
\label{subsec:epistemic-logic}

Hintikka~\citep{hintikka1962knowledge} pioneered epistemic logic with the operator
$K\phi$ (``the agent knows $\phi$''). Standard systems include:

\begin{description}
  \item[K (Distribution):] $K(\phi \to \psi) \to (K\phi \to K\psi)$
  \item[T (Veridicality):] $K\phi \to \phi$
  \item[4 (Positive Introspection):] $K\phi \to KK\phi$
  \item[5 (Negative Introspection):] $\lnot K\phi \to K\lnot K\phi$
\end{description}

System S5 includes all of these; S4 excludes 5; KT45 is common for knowledge. For
belief (which can be mistaken), T is typically dropped.

\paragraph{Limitations for CLAIR.}
Standard epistemic logic is binary: either the agent knows/believes $\phi$ or not.
There is no representation of degrees of belief. Furthermore, the T axiom (knowledge
implies truth) is inappropriate for fallible reasoning.

\subsection{Provability Logic}
\label{subsec:provability-logic}

Provability logic, systematized by Boolos~\citep{boolos1993logic}, interprets
$\Box\phi$ as ``$\phi$ is provable in Peano Arithmetic'' (or another formal system).
The central system is GL (G\"odel-L\"ob logic), with axioms:

\begin{description}
  \item[K (Distribution):] $\Box(\phi \to \psi) \to (\Box\phi \to \Box\psi)$
  \item[4 (Positive Introspection):] $\Box\phi \to \Box\Box\phi$
  \item[L (L\"ob's Axiom):] $\Box(\Box\phi \to \phi) \to \Box\phi$
\end{description}

Notably, GL omits:
\begin{itemize}
  \item T ($\Box\phi \to \phi$): Provability does not imply truth. A system can prove
        false statements if inconsistent.
  \item 5 (Negative Introspection): Unprovability is not always recognizable.
\end{itemize}

\paragraph{L\"ob's Theorem.}
L\"ob's axiom (L) captures a profound limitation. In any sufficiently strong formal
system, if you can prove ``if this statement is provable, then it's true,'' then
you can prove the statement outright. Formally:
\[
  \vdash \Box(\Box\phi \to \phi) \to \Box\phi
\]

A corollary: no consistent system can prove its own soundness (that $\Box\phi \to \phi$
holds for all $\phi$). If it could, L\"ob's axiom would yield proofs of everything.

\paragraph{Semantics.}
GL is sound and complete for Kripke frames that are \emph{transitive} and \emph{converse
well-founded} (no infinite ascending chains $w_1 R w_2 R w_3 \ldots$). Intuitively,
every ``higher'' world is closer to $\omega$-consistency.

\paragraph{Relevance to CLAIR.}
CLAIR's approach to self-reference is directly inspired by GL. A belief system
reasoning about its own beliefs faces L\"obian constraints: it cannot coherently
believe in its own soundness without qualification. CLAIR's stratification mechanism
and Confidence-Bounded Provability Logic (CPL, \Cref{ch:self-reference}) formalize
how to reason about self-referential beliefs while respecting these limits.

\subsection{Graded and Fuzzy Modal Logics}
\label{subsec:graded-modal}

Several traditions extend modal logic to graded settings:

\paragraph{Graded modalities.}
De Rijke and Fine~\citep{fine1972conjunction,derijke2000graded} introduce operators
$\Box_n$ meaning ``at least $n$ accessible worlds satisfy $\phi$.'' This is not
about truth degrees but about counting accessible worlds.

\paragraph{Fuzzy modal logic.}
Godo, Esteva, and colleagues~\citep{bou2011minimum,godo2011fuzzy} develop modal logics
over many-valued semantics (G\"odel, \L ukasiewicz, Product). The accessibility
relation $R : W \times W \to [0,1]$ assigns degrees, and:
\[
  V_w(\Box\phi) = \inf_{w'} \max\{1 - R(w,w'), V_{w'}(\phi)\}
\]

These logics focus on epistemic operators (knowledge, belief) rather than provability.

\paragraph{The gap CLAIR fills.}
Despite extensive work on fuzzy/graded epistemic logic, there is no prior work combining:
\begin{enumerate}
  \item Graded truth values in $[0,1]$
  \item Provability-style semantics (transitive, converse well-founded frames)
  \item L\"ob's axiom or its graded analog
\end{enumerate}
CLAIR's CPL (\Cref{ch:self-reference}) fills this gap, introducing a graded L\"ob
axiom with a discount function that prevents confidence bootstrapping.

\section{Truth Maintenance and Argumentation}
\label{sec:tms-arg}

Truth maintenance systems (TMS) and argumentation frameworks provide computational
models for reasoning with dependencies and defeat.

\subsection{Justification-based TMS}
\label{subsec:jtms}

Doyle's JTMS~\citep{doyle1979truth} tracks why beliefs are held. Each node (belief)
has a justification:
\begin{itemize}
  \item \textbf{IN-list}: nodes that must be believed for this belief to be believed
  \item \textbf{OUT-list}: nodes that must \emph{not} be believed
\end{itemize}

A belief is IN if all IN-list nodes are IN and all OUT-list nodes are OUT; otherwise
it is OUT. When a node's status changes, dependencies propagate.

\paragraph{Example.}
\begin{verbatim}
  Node: use-hs256
  Justification: (IN: [stateless-req, secret-available], OUT: [multi-service])
\end{verbatim}
The belief \texttt{use-hs256} is IN iff \texttt{stateless-req} and \texttt{secret-available}
are IN and \texttt{multi-service} is OUT.

\paragraph{Limitations.}
JTMS is binary: beliefs are either IN or OUT, with no gradation. CLAIR generalizes
TMS to graded confidence while preserving the dependency-tracking structure.

\subsection{Assumption-based TMS}
\label{subsec:atms}

De Kleer's ATMS~\citep{dekleer1986assumption} tracks multiple consistent states
simultaneously. Instead of labeling nodes IN/OUT, each node is labeled with
\emph{environments}---sets of assumptions under which it holds.

\begin{verbatim}
  Node: use-hs256
  Environments: {{A1, A2}, {A1, A3}}
  -- Believed under assumptions (A1 ∧ A2) or (A1 ∧ A3)
\end{verbatim}

ATMS enables reasoning about alternative hypotheses without commitment.

\paragraph{Relevance to CLAIR.}
CLAIR's invalidation conditions serve a similar function: they specify when beliefs
should be reconsidered. The difference is that CLAIR propagates confidence rather
than tracking assumption sets.

\subsection{Argumentation Frameworks}
\label{subsec:argumentation}

Dung's abstract argumentation framework (AAF)~\citep{dung1995acceptability} represents
arguments as nodes and attacks as directed edges. Various semantics define which
arguments are acceptable:
\begin{itemize}
  \item \textbf{Grounded extension}: Unique, includes only unattacked arguments and
        those defended by them.
  \item \textbf{Preferred extension}: Maximal admissible sets.
\end{itemize}

\paragraph{Gradual semantics.}
Amgoud, Ben-Naim, and others~\citep{amgoud2023weighted,bonzon2016comparative} extend
AAF with weighted arguments and continuous acceptability:
\[
  \text{strength}(a) = \frac{w(a)}{1 + \sum_{b \text{ attacks } a} \text{strength}(b)}
\]

\paragraph{Relevance to CLAIR.}
CLAIR's defeat semantics draws on gradual argumentation. Our undercut formula
$c' = c \times (1 - d)$ and rebut formula $c' = c_{\text{for}} / (c_{\text{for}} + c_{\text{against}})$
are novel contributions that compose with the confidence algebra.

\subsection{Pollock's Defeaters}
\label{subsec:pollock}

Pollock~\citep{pollock1987defeasible,pollock2001defeasible} distinguishes two types
of defeaters:
\begin{description}
  \item[Rebutting defeaters] attack the conclusion directly with contrary evidence.
  \item[Undercutting defeaters] attack the inference without attacking the conclusion.
\end{description}

Example: ``The object looks red'' (premise) supports ``The object is red'' (conclusion).
\begin{itemize}
  \item Rebutting: ``I have testimony that the object is blue.''
  \item Undercutting: ``The room has red lighting.''
\end{itemize}

\paragraph{Relevance to CLAIR.}
CLAIR adopts Pollock's distinction. Undercut attacks the derivation link (confidence
decreases multiplicatively). Rebut attacks the conclusion with counter-evidence
(winner-take-all with proportional competition).

\section{Belief Revision}
\label{sec:belief-revision-bg}

How should beliefs change in response to new information? The AGM framework provides
the canonical answer.

\subsection{The AGM Framework}
\label{subsec:agm}

Alchourr\'on, G\"ardenfors, and Makinson~\citep{alchourron1985logic} axiomatize rational
belief change. A belief set $K$ is a deductively closed set of sentences. Three
operations are defined:
\begin{description}
  \item[Expansion $K + \phi$]: Add $\phi$ and close under deduction.
  \item[Contraction $K - \phi$]: Remove $\phi$ minimally.
  \item[Revision $K * \phi$]: Add $\phi$, possibly removing conflicting beliefs.
\end{description}

The Levi identity connects them: $K * \phi = (K - \lnot\phi) + \phi$.

\paragraph{Key postulates for contraction.}
\begin{description}
  \item[Closure]: $K - \phi$ is deductively closed.
  \item[Success]: If $\phi \notin \text{Cn}(\emptyset)$, then $\phi \notin K - \phi$.
  \item[Inclusion]: $K - \phi \subseteq K$.
  \item[Vacuity]: If $\phi \notin K$, then $K - \phi = K$.
  \item[Recovery]: $K \subseteq (K - \phi) + \phi$.
  \item[Extensionality]: If $\phi \leftrightarrow \psi$, then $K - \phi = K - \psi$.
\end{description}

\paragraph{The controversial Recovery postulate.}
Recovery states that if we contract by $\phi$ and then expand by $\phi$, we recover
the original belief set. This is controversial: intuitively, contracting by $\phi$
should lose more than just $\phi$---it should also lose the specific evidence that
supported $\phi$. Re-adding $\phi$ doesn't restore that evidence.

\paragraph{Epistemic entrenchment.}
G\"ardenfors~\citep{gardenfors1988knowledge} introduces entrenchment ordering:
$\phi \leq_\epsilon \psi$ iff giving up $\phi$ is at least as acceptable as giving
up $\psi$. More entrenched beliefs are retained during contraction.

\subsection{Ranking Theory}
\label{subsec:ranking-theory}

Spohn~\citep{spohn2012laws} develops an ordinal approach. A ranking function
$\kappa : W \to \mathbb{N} \cup \{\infty\}$ assigns natural numbers to possible worlds,
with $\kappa(w) = 0$ for the most plausible worlds. Belief degree is defined:
\[
  \beta(\phi) = \kappa(\lnot\phi) = \min\{\kappa(w) : w \models \lnot\phi\}
\]

Ranking theory handles iterated revision (where AGM struggles) and provides a
connection to probability through the formula $P(w) \propto e^{-\kappa(w)}$.

\subsection{Dynamic Epistemic Logic}
\label{subsec:del}

Van Ditmarsch, van der Hoek, and Kooi~\citep{van2007dynamic} develop modal operators
for belief change:
\begin{itemize}
  \item $[\phi!]\psi$: ``After publicly announcing $\phi$, $\psi$ holds.''
  \item Action models generalize to arbitrary epistemic actions.
\end{itemize}

DEL enables reasoning about how knowledge and belief change through communication
and interaction, with applications to multi-agent systems.

\subsection{Relevance to CLAIR}
\label{subsec:revision-clair-connection}

CLAIR extends AGM in three ways:
\begin{enumerate}
  \item \textbf{Graded beliefs}: Confidence replaces binary membership.
  \item \textbf{Structured justification}: Revision operates on the justification DAG,
        not just the belief set.
  \item \textbf{Recovery failure}: Recovery correctly fails---evidence has specific
        strength, and retracting a belief loses that evidence.
\end{enumerate}

CLAIR's revision algorithm (modify graph $\to$ identify affected $\to$ recompute
confidence) is a graded generalization of TMS dependency-directed backtracking.

\section{Type-Theoretic Approaches to Uncertainty}
\label{sec:type-theory-bg}

Type theory provides the programming language substrate for CLAIR. We survey
approaches to tracking metadata through computation.

\subsection{Information Flow Types}
\label{subsec:info-flow}

Myers and Sabelfeld~\citep{myers1999jflow,sabelfeld2003language} develop type systems
that track security levels (confidentiality, integrity) through computation:
\begin{verbatim}
  int{Alice -> Bob} x;   // Alice owns, Bob can read
  int{Alice -> *}   y;   // Alice owns, public
  y = x;                 // ERROR: would leak to public
\end{verbatim}

The type system prevents information leakage at compile time.

\paragraph{Relevance to CLAIR.}
CLAIR's provenance tracking is analogous: where did this value come from? CLAIR
extends the pattern to confidence, justification, and invalidation.

\subsection{Refinement Types}
\label{subsec:refinement}

Rondon, Kawaguchi, and Jhala~\citep{rondon2008liquid} introduce Liquid Types, extending
Hindley-Milner with logical predicates:
\begin{verbatim}
  {-@ type Nat = {v:Int | v >= 0} @-}
  {-@ type Pos = {v:Int | v > 0}  @-}

  {-@ div :: Int -> Pos -> Int @-}
  div x y = x `quot` y   -- y cannot be 0
\end{verbatim}

Refinements are checked statically via SMT solvers.

\paragraph{Relevance to CLAIR.}
Some CLAIR constraints could be expressed as refinements (e.g., confidence in $[0,1]$).
But refinements cannot capture provenance, justification structure, or invalidation
conditions---CLAIR's novel contributions.

\subsection{Dependent Types and Proof Assistants}
\label{subsec:dependent}

The Curry-Howard correspondence identifies types with propositions and programs with
proofs. Dependent type systems (Coq, Agda, Idris, Lean) exploit this for formal
verification:
\begin{verbatim}
  def div (x : Nat) (y : Nat) (h : y > 0) : Nat := x / y
  -- Must provide proof h that y > 0
\end{verbatim}

The proof is a value, checked by the type system.

\paragraph{Relevance to CLAIR.}
CLAIR extends Curry-Howard: programs are not just proofs but \emph{beliefs with
justifications}. A CLAIR program carries:
\begin{itemize}
  \item The value (what is believed)
  \item Confidence (how strongly)
  \item Provenance (from where)
  \item Justification (why)
  \item Invalidation conditions (when to reconsider)
\end{itemize}

\subsection{Probabilistic Programming}
\label{subsec:prob-programming}

Probabilistic programming languages (Church~\citep{goodman2008church}, Stan, Pyro, Gen)
represent and manipulate probability distributions as first-class values:
\begin{verbatim}
  (define (coin-model)
    (let ((fair? (flip 0.9)))
      (if fair? (flip 0.5) (flip 0.9))))
\end{verbatim}

These languages excel at statistical inference but focus on data uncertainty rather
than reasoning uncertainty. They require probabilistic normalization and lack
explicit justification structure.

\subsection{Justification Logic}
\label{subsec:justification-logic}

Artemov~\citep{artemov2001explicit,artemov2019justification} extends modal logic with
explicit justification terms. Instead of $\Box\phi$ (``$\phi$ is known/believed''),
we write $t : \phi$ (``$t$ is a justification for $\phi$''). Terms include:
\begin{align}
  t &::= c \mid x \mid t \cdot t \mid t + t \mid !t
\end{align}
where $c$ is a constant (axiom), $x$ is a variable, $s \cdot t$ is application
(modus ponens), $t + s$ is sum (either justification suffices), and $!t$ is proof
checking ($t$ justifies that $t$ justifies $\phi$).

The key axiom is application:
\[
  s : (\phi \to \psi) \to (t : \phi \to (s \cdot t) : \psi)
\]

\paragraph{Limitations.}
Justification Logic produces tree-structured justifications (each conclusion from
fresh premises). It cannot represent:
\begin{itemize}
  \item Shared premises (same evidence supporting multiple conclusions)
  \item Defeasible reasoning (defeat edges)
  \item Graded confidence
\end{itemize}

\paragraph{CLAIR's extension.}
CLAIR adopts Justification Logic's core idea (explicit justification terms) but
extends it to:
\begin{enumerate}
  \item \textbf{DAGs}: Shared premises create graph structure.
  \item \textbf{Labeled edges}: Support, undercut, and rebut edges.
  \item \textbf{Graded confidence}: Each node carries confidence in $[0,1]$.
\end{enumerate}

\section{Synthesis: The Gap CLAIR Fills}
\label{sec:synthesis}

Table~\ref{tab:prior-art-synthesis} summarizes the prior art and CLAIR's extensions.

\begin{table}[ht]
\centering
\begin{tabular}{lll}
\toprule
\textbf{Concept} & \textbf{Prior Work} & \textbf{CLAIR Extension} \\
\midrule
Uncertainty & Subjective Logic & Epistemic confidence (about reasoning) \\
Provenance & Database provenance & Computation provenance + invalidation \\
Justification & Justification Logic & DAGs with labeled edges, defeat \\
Belief revision & TMS, AGM & Graded, justification-based revision \\
Design rationale & IBIS/QOC & First-class decisions in language \\
Refinements & Liquid Types & + confidence + invalidation \\
Effects & Effect systems & + intent + semantic meaning \\
Self-reference & Provability Logic (GL) & Graded L\"ob (CPL) \\
Multi-agent & Arrow, Condorcet & Pragmatic internal realism \\
\bottomrule
\end{tabular}
\caption{Prior art and CLAIR extensions}
\label{tab:prior-art-synthesis}
\end{table}

\paragraph{The gap.}
No prior work combines:
\begin{enumerate}
  \item Beliefs as first-class typed values with epistemic metadata
  \item Confidence as non-probabilistic epistemic commitment
  \item Justification as labeled DAGs with defeat semantics
  \item Self-reference constraints derived from provability logic
  \item Belief revision operating on justification structure
\end{enumerate}

CLAIR provides this synthesis, offering a rigorous foundation for AI systems that
can explain and audit their own reasoning while honestly representing epistemic
limitations.

\paragraph{Key influences.}
We acknowledge particular debts to:
\begin{itemize}
  \item De Kleer's ATMS~\citep{dekleer1986assumption} for dependency-directed reasoning
  \item J\o sang's Subjective Logic~\citep{josang2016subjective} for uncertainty algebra
  \item Boolos's provability logic~\citep{boolos1993logic} for self-reference treatment
  \item Pollock's defeater theory~\citep{pollock1987defeasible} for defeat semantics
  \item Artemov's Justification Logic~\citep{artemov2019justification} for explicit justifications
\end{itemize}

CLAIR is not a rejection of this prior work but a synthesis that combines their
insights into a coherent type-theoretic framework.

%% ============================================================================
%% BIBLIOGRAPHY NOTES
%% ============================================================================
%
% Key citations for this chapter:
%
% Epistemology:
% - bonjour1985structure
% - klein1999human, klein2003infinite, klein2005infinitism
% - sellars1956empiricism
%
% Modal/Provability Logic:
% - hintikka1962knowledge
% - boolos1993logic
% - bou2011minimum
%
% TMS/Argumentation:
% - doyle1979truth
% - dekleer1986assumption
% - dung1995acceptability
% - pollock1987defeasible
% - amgoud2023weighted
%
% Belief Revision:
% - alchourron1985logic
% - gardenfors1988knowledge
% - spohn2012laws
% - van2007dynamic
%
% Type Theory:
% - myers1999jflow, sabelfeld2003language
% - rondon2008liquid
% - goodman2008church
% - artemov2001explicit, artemov2019justification
%
% Subjective Logic:
% - josang2016subjective
%

